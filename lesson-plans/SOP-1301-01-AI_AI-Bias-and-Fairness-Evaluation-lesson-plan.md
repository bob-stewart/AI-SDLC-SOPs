# Lesson Plan Draft: SOP-1301-01-AI_AI-Bias-and-Fairness-Evaluation

**SOP Reference:** SOP-1301-01-AI_AI-Bias-and-Fairness-Evaluation

## Objective

The purpose of this Standard Operating Procedure (SOP) is to establish a robust, standardized process for identifying, monitoring, and mitigating bias in AI systems developed or deployed within the organization. The SOP ensures that fairness considerations are consistently integrated into every phase of the AI Systems Development Life Cycle (AI-SDLC), thereby enhancing trust, compliance, and ethical alignment with regulatory requirements, including those mandated by the AI-IRB (Artificial Intelligence Institutional Review Board).

## Audience & Applicability

Applies to. Includes focus areas such as Applies To and Exclusions.

## Key Definitions

- No key definitions provided.

## Key Roles

- **AI-IRB Chair & Members**: Review bias/fairness plans, verify compliance with policy and legal obligations, issue approval or corrective directions.
- **Project Sponsor/Product Owner**: Ensure scope, timeline, and budget include bias & fairness tasks; respond to IRB feedback and incorporate changes.
- **Data Scientists / ML Engineers**: Implement technical aspects of bias detection, fairness metrics, propose remediation solutions.
- **QA / Validation Team**: Independently test for bias using established metrics and verifying the data scientists' results.
- **AI Governance Office**: Maintain official documentation on bias/fairness evaluations, track compliance, liaise with IRB and Product Owners.
- **Operations / Deployment Team**: Incorporate final bias remediation steps into production environment, coordinate logs/monitoring for bias detection.
- **Technical Support**: Gather user feedback on potential unfair outcomes, funnel issues to QA or Data Scientists for re-check.

